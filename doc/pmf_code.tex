\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Probabilistic Gradient Descent},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Probabilistic Gradient Descent}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  

\begin{document}
\maketitle

\hypertarget{step-1-load-data-and-train-test-split}{%
\subsubsection{Step 1 Load Data and Train-test
Split}\label{step-1-load-data-and-train-test-split}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(tidyr)}
\KeywordTok{library}\NormalTok{(MASS)}
\KeywordTok{library}\NormalTok{(ggplot2)}
\NormalTok{data <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"../data/ml-latest-small/ratings.csv"}\NormalTok{)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{0}\NormalTok{)}
\NormalTok{test_idx <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(data), }\KeywordTok{round}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(data)}\OperatorTok{/}\DecValTok{5}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\NormalTok{train_idx <-}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(data), test_idx)}
\NormalTok{data_train <-}\StringTok{ }\NormalTok{data[train_idx,]}
\NormalTok{data_test <-}\StringTok{ }\NormalTok{data[test_idx,]}
\end{Highlighting}
\end{Shaded}

\hypertarget{step-2-matrix-factorization}{%
\subsubsection{Step 2 Matrix
Factorization}\label{step-2-matrix-factorization}}

\hypertarget{step-2.1-algorithm-and-regularization}{%
\paragraph{Step 2.1 Algorithm and
Regularization}\label{step-2.1-algorithm-and-regularization}}

A2. \href{./paper/P3\%20probabilistic-matrix-factorization.pdf}{Gradient
Descent with Probabilistic Assumptions} Section 2

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{U <-}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(data}\OperatorTok{$}\NormalTok{userId))}
\NormalTok{I <-}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(data}\OperatorTok{$}\NormalTok{movieId))}
\KeywordTok{source}\NormalTok{(}\StringTok{"../lib/Matrix_Factorization_pmf.R"}\NormalTok{)}
\CommentTok{#RMSE function}
\NormalTok{RMSE <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(rating, est_rating)\{}
\NormalTok{  sqr_err <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(obs)\{}
\NormalTok{    sqr_error <-}\StringTok{ }\NormalTok{(obs[}\DecValTok{3}\NormalTok{] }\OperatorTok{-}\StringTok{ }\NormalTok{est_rating[}\KeywordTok{as.character}\NormalTok{(obs[}\DecValTok{2}\NormalTok{]), }\KeywordTok{as.character}\NormalTok{(obs[}\DecValTok{1}\NormalTok{])])}\OperatorTok{^}\DecValTok{2}
    \KeywordTok{return}\NormalTok{(sqr_error)}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{apply}\NormalTok{(rating, }\DecValTok{1}\NormalTok{, sqr_err))))  }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{step-2.2-parameter-tuning}{%
\paragraph{Step 2.2 Parameter Tuning}\label{step-2.2-parameter-tuning}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#load PMF algorithm}
\KeywordTok{source}\NormalTok{(}\StringTok{"../lib/cross_validation_pmf.R"}\NormalTok{)}
\CommentTok{#set list of feature combination}
\NormalTok{f_l =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{),}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#cross-validation with K = 5}
\NormalTok{result_summary <-}\StringTok{ }\KeywordTok{array}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(f_l), }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{)) }
\NormalTok{run_time <-}\StringTok{ }\KeywordTok{system.time}\NormalTok{(}\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(f_l))\{}
\NormalTok{    par <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\StringTok{"f = "}\NormalTok{, f_l[i,}\DecValTok{1}\NormalTok{], }\StringTok{", sigma_p = "}\NormalTok{, f_l[i,}\DecValTok{2}\NormalTok{],}\StringTok{", sigma_q = "}\NormalTok{, f_l[i,}\DecValTok{3}\NormalTok{])}
    \KeywordTok{cat}\NormalTok{(par, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    current_result <-}\StringTok{ }\KeywordTok{cv.function_pmf}\NormalTok{(data, }\DataTypeTok{K =} \DecValTok{5}\NormalTok{, }\DataTypeTok{f =}\NormalTok{ f_l[i,}\DecValTok{1}\NormalTok{],}\DataTypeTok{sigma_p=}\NormalTok{f_l[i,}\DecValTok{2}\NormalTok{],}\DataTypeTok{sigma_q=}\NormalTok{ f_l[i,}\DecValTok{3}\NormalTok{],}\DataTypeTok{sigma =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{    result_summary[,,i] <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(current_result), }\DataTypeTok{ncol =} \DecValTok{5}\NormalTok{, }\DataTypeTok{byrow =}\NormalTok{ T) }
    \KeywordTok{print}\NormalTok{(result_summary)}
\NormalTok{\})}
\KeywordTok{save}\NormalTok{(result_summary, }\DataTypeTok{file =} \StringTok{"../output/pmf/rmse_pmf.Rdata"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#plot the rmse result of cross-validation}
\KeywordTok{load}\NormalTok{(}\StringTok{"../output/pmf/rmse_pmf.Rdata"}\NormalTok{)}
\NormalTok{rmse_pmf <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{rbind}\NormalTok{(}\KeywordTok{t}\NormalTok{(result_summary[}\DecValTok{1}\NormalTok{,,]), }\KeywordTok{t}\NormalTok{(result_summary[}\DecValTok{2}\NormalTok{,,])), }\DataTypeTok{train_test =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Train"}\NormalTok{, }\StringTok{"Test"}\NormalTok{), }\DataTypeTok{each =} \DecValTok{4}\NormalTok{), }\DataTypeTok{par =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"f = "}\NormalTok{, f_l[,}\DecValTok{1}\NormalTok{], }\StringTok{", sigma_p = "}\NormalTok{, f_l[,}\DecValTok{2}\NormalTok{], }\StringTok{", sigma_q = "}\NormalTok{, f_l[,}\DecValTok{3}\NormalTok{]), }\DataTypeTok{times =} \DecValTok{2}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{gather}\NormalTok{(}\StringTok{"epoch"}\NormalTok{, }\StringTok{"RMSE"}\NormalTok{, }\OperatorTok{-}\NormalTok{train_test, }\OperatorTok{-}\NormalTok{par)}
\NormalTok{rmse_pmf}\OperatorTok{$}\NormalTok{epoch <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{gsub}\NormalTok{(}\StringTok{"X"}\NormalTok{, }\StringTok{""}\NormalTok{, rmse_pmf}\OperatorTok{$}\NormalTok{epoch))}
\NormalTok{rmse_pmf }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ epoch, }\DataTypeTok{y =}\NormalTok{ RMSE, }\DataTypeTok{col =}\NormalTok{ train_test)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{facet_grid}\NormalTok{(}\OperatorTok{~}\NormalTok{par)}
\end{Highlighting}
\end{Shaded}

\includegraphics{pmf_code_files/figure-latex/unnamed-chunk-5-1.pdf}

\hypertarget{step-3-postprocessing}{%
\subsubsection{Step 3 Postprocessing}\label{step-3-postprocessing}}

After matrix factorization, postporcessing will be performed to improve
accuracy. The referenced papers are:

P2:{[}Postprocessing SVD with KNN{]}, ``Improving regularized singular
value decomposition for collaborative filtering'', Section 3.5

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#fit model with best parameters chosen from CV.}
\NormalTok{result <-}\StringTok{ }\KeywordTok{gradesc_pmf}\NormalTok{(}\DataTypeTok{f =} \DecValTok{10}\NormalTok{, }\DataTypeTok{sigma_p =} \FloatTok{0.5}\NormalTok{,}\DataTypeTok{sigma_q =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{lrate =} \FloatTok{0.01}\NormalTok{, }\DataTypeTok{max.iter =} \DecValTok{100}\NormalTok{, }\DataTypeTok{stopping.deriv =} \FloatTok{0.01}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ data, }\DataTypeTok{train =}\NormalTok{ data_train, }\DataTypeTok{test =}\NormalTok{ data_test)}

\KeywordTok{save}\NormalTok{(result, }\DataTypeTok{file =} \StringTok{"../output/pmf/mat_fac_pmf.RData"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{load}\NormalTok{(}\DataTypeTok{file =} \StringTok{"../output/pmf/mat_fac_pmf.RData"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(lsa)}

\NormalTok{cossim_mat <-}\StringTok{ }\KeywordTok{cosine}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(result[[}\StringTok{"q"}\NormalTok{]]))}
\KeywordTok{save}\NormalTok{(cossim_mat, }\DataTypeTok{file =} \StringTok{"../output/pmf/cossim.Rdata"}\NormalTok{)}
\NormalTok{closest <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\KeywordTok{ncol}\NormalTok{(result[[}\StringTok{"q"}\NormalTok{]]))}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(result[[}\StringTok{"q"}\NormalTok{]]))\{}
\NormalTok{  x<-}\StringTok{ }\NormalTok{cossim_mat[i,]}
\NormalTok{  x<-}\KeywordTok{t}\NormalTok{(x)}
\NormalTok{  closest[i] <-}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{grepl}\NormalTok{(}\KeywordTok{max}\NormalTok{(x[}\OperatorTok{-}\KeywordTok{which.max}\NormalTok{(x)]),x))}\CommentTok{# return the second highest cosine sim (drop itself).}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate the mean rate for different movies}
\NormalTok{meanrate <-}\StringTok{ }\NormalTok{data}\OperatorTok{%>%}\KeywordTok{group_by}\NormalTok{(movieId)}\OperatorTok{%>%}\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean_rating=}\KeywordTok{mean}\NormalTok{(rating))}
\CommentTok{# median}
\NormalTok{medianrate <-}\StringTok{ }\NormalTok{data}\OperatorTok{%>%}\KeywordTok{group_by}\NormalTok{(movieId)}\OperatorTok{%>%}\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{median_rating=}\KeywordTok{median}\NormalTok{(rating))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{DAT<-data}
\NormalTok{DAT <-}\StringTok{ }\NormalTok{DAT [,}\OperatorTok{-}\DecValTok{4}\NormalTok{]}
\NormalTok{DAT <-}\StringTok{ }\NormalTok{DAT }\OperatorTok{%>%}\StringTok{ }\KeywordTok{spread}\NormalTok{(movieId, rating)}
\NormalTok{DAT1 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{index=}\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5931640}\NormalTok{))}
\NormalTok{DAT1}\OperatorTok{$}\NormalTok{y <-}\KeywordTok{as.vector}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(DAT[,}\OperatorTok{-}\DecValTok{1}\NormalTok{]))}
\NormalTok{DAT1}\OperatorTok{$}\NormalTok{movieId<-}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{9724}\NormalTok{, }\DataTypeTok{times =} \DecValTok{610}\NormalTok{)}
\NormalTok{DAT1}\OperatorTok{$}\NormalTok{userId <-}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{610}\NormalTok{, }\DataTypeTok{times =} \DecValTok{9724}\NormalTok{)}


\CommentTok{#add X2}
\NormalTok{knn_rating <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (m }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{9724}\NormalTok{) \{}
\NormalTok{  knn_rating[m] <-}\StringTok{ }\NormalTok{meanrate[closest[m], }\DecValTok{2}\NormalTok{]}
\NormalTok{\}}
\NormalTok{knn_rating<-}\KeywordTok{unlist}\NormalTok{(knn_rating)}
\NormalTok{DAT1}\OperatorTok{$}\NormalTok{KNN<-}\StringTok{ }\KeywordTok{rep}\NormalTok{(knn_rating, }\DataTypeTok{times =}\DecValTok{610}\NormalTok{)}

\CommentTok{# prepare x1 predictor}
\NormalTok{q <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(result[[}\StringTok{"q"}\NormalTok{]])}
\NormalTok{p <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(result[[}\StringTok{"p"}\NormalTok{]])}
\NormalTok{r<-}\KeywordTok{t}\NormalTok{(p)}\OperatorTok{%*%}\NormalTok{q}
\NormalTok{x1<-}\KeywordTok{as.vector}\NormalTok{(r)}

\NormalTok{DAT1}\OperatorTok{$}\NormalTok{X1<-x1}

\CommentTok{# remove NA}

\NormalTok{DAT2<-}\KeywordTok{na.omit}\NormalTok{(DAT1)}
\NormalTok{DAT2<-DAT2[,}\OperatorTok{-}\DecValTok{1}\NormalTok{]}

\CommentTok{# regression model}

\NormalTok{reg<-}\KeywordTok{lm}\NormalTok{(y}\OperatorTok{~}\NormalTok{KNN}\OperatorTok{+}\NormalTok{X1,}\DataTypeTok{data=}\NormalTok{DAT2)}
\KeywordTok{summary}\NormalTok{(reg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ KNN + X1, data = DAT2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.7113 -0.4363  0.0471  0.4718  7.4922 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 0.586393   0.014835  39.527   <2e-16 ***
## KNN         0.003548   0.003020   1.175     0.24    
## X1          0.886773   0.003238 273.889   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.7895 on 100833 degrees of freedom
## Multiple R-squared:  0.4266, Adjusted R-squared:  0.4266 
## F-statistic: 3.751e+04 on 2 and 100833 DF,  p-value: < 2.2e-16
\end{verbatim}

According to the coefficients of fitted linear model, the knn ratings
does not have a significant influence on the prediction result we get
from probablistic gradient descent. Therefore we simply drop this term
and keep the original P and Q for evaluation.

\hypertarget{step-4-evaluation}{%
\subsubsection{Step 4 Evaluation}\label{step-4-evaluation}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}

\NormalTok{RMSE <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{epochs =} \KeywordTok{seq}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{20}\NormalTok{), }\DataTypeTok{Training_MSE =}\NormalTok{ result}\OperatorTok{$}\NormalTok{train_RMSE, }\DataTypeTok{Test_MSE =}\NormalTok{ result}\OperatorTok{$}\NormalTok{test_RMSE) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =}\NormalTok{ train_or_test, }\DataTypeTok{value =}\NormalTok{ RMSE, }\OperatorTok{-}\NormalTok{epochs)}

\NormalTok{RMSE }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ epochs, }\DataTypeTok{y =}\NormalTok{ RMSE,}\DataTypeTok{col =}\NormalTok{ train_or_test)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{scale_x_discrete}\NormalTok{(}\DataTypeTok{limits =} \KeywordTok{seq}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{20}\NormalTok{)) }\OperatorTok{+}\StringTok{ }\KeywordTok{xlim}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Scale for 'x' is already present. Adding another scale for 'x', which
## will replace the existing scale.
\end{verbatim}

\includegraphics{pmf_code_files/figure-latex/unnamed-chunk-10-1.pdf}

From the plots of RMSE's of PMF and SGD in the first part, we can see
the prediction power of SGD and PMF are almost the same in this case.
The possible reasons is: the two algorithms both belong to gradient
descent category so they have the similar calculation flow throughout
the limited number of iterations.


\end{document}
